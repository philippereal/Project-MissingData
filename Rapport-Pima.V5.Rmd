---
title: "Rapport - Données manquantes"
output:
  html_document:
    df_print: paged
  toc : yes 
  pdf_document: default
---

#### Nom et Prénom des étudiants du groupe :

```
- Nom : Prénom : REAL Philippe
- Nom : Prénom : GUYONVARCH Alexis
```

### 1. Introduction

Présentation des données et objectifs de l'étude
https://www.kaggle.com/uciml/pima-indians-diabetes-database

#### 1.1 Contexte

Le jeu de données provient de l'Institut national du diabete, des maladies digestives et rénales. Il rend possible la prédiction de la pathologie, en l'espèce le diabète, pour le patient  à partir d'analyses inclues dans le jeu de données. Dans l'extraction, les patients sont des femmes et issues de la commmunauté des indiens Pima.

#### 1.2 Description des colonnes

* npreg            : Number of times pregnant - Nombre de grossesses
* glu              : GlucosePlasma 2 hours in an oral glucose tolerance test - Concentration de glucose dans le sang
* bp               : BloodPressureDiastolic - Pression sanguine (mm Hg)
* skin             : SkinThicknessTriceps - Epaisseur de la peau (mm)
* Insuline         : Insulin 2- Hour serum insuline - Taux d'insuline présent dans le sang (mu U/ml)
* bmi              : BMIBody mass index - Indice de masse corporelle (poids en kg/(taille en m)élevée au carré)
* ped              : Diabetes Pedigree Function Diabetes pedigree function - Antécédent de diabète sucrégénétique
* age              : Age (years)
* type             : Outcome Class variable - Variable réponse binaire (0/1)

#### 1.3 Objectifs

Objectif : prédire si l'individu a ou non le diabète. 
Préalablement, il s'agi de compléter les données manquante par imputation.

#### 1.4 Chargement des donnés - Résumé

```{r, option} 
rm(list=ls())

knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  fig.align = "center",
  fig.retina = 2, 
  fig.width = 10,
  cache=TRUE, 
  cache.lazy = FALSE
  )
# Librairies
library(MASS);
library(missMDA);
library(mice);
library(VIM)
library(FactoMineR)
library(ggplot2)
library(factoextra)
library(corrplot)
library(leaps)
library(psych)
library(sampSurf)
```

```{r import}
#setwd("D:/R exercices/DONNEES MANQUANTES/Projet")
data<-read.table(file="Pima_DataWithNA.txt",sep=";" ,header=T, na.strings = "NA")
# Description du jeu de données
describe(data[,-1])
# Elements de cadrage sur les données manquantes
pMiss <- function(x){round(sum(is.na(x))/length(x)*100,digits=1)}
stat.miss <- apply(data[,-1],2,pMiss)
print('Pourcentage de données manquantes par variable')
print('-----------------------------------------------------------------------------')
stat.miss
```

* Traitement des données

Suppression de la 1ère colonne comprenant les identifants.
La colonne insuline est, dans l'immédiat, conservée en dépit de la part importante de données manquantes : 48.7 %.

```{r traitement}

tab_Pima1<-data[,-1]
#tab_Pima1<-tab_Pima1[,-5]# La colonne insuline est dans l'immédiat conservée
maxDim<-9 #8 si on décide de supprimer la colonne insuline
data_Pima1<-as.data.frame.matrix(tab_Pima1)
data_Pima1$type <- as.logical(data_Pima1$type)
dataPima<-data_Pima1[,1:maxDim]
dataPima<- as.data.frame(dataPima)

describe(dataPima[,-9])

```

* Les différentes catégories de données manquantes sont "taguées" en vue d'analyses ultérieures.
La description deux à deux des patterns est effectuée avec avec la fonction md.pairs() du package mice qui nous permet déjà de mettre en lumière les 10 combinaisons du jeu de données parmi les 28 possibles.

```{r tags, warning=F, message=F}

##Tager des données qui seront ultérieurement complétées
attach(dataPima)
comb.miss <- md.pairs(dataPima[,2:6])
print("Combinaisons 2 à 2 des données manquantes")
comb.miss$mm

glu.na <- row.names(dataPima[is.na(glu),0])
bp.na<-row.names(dataPima[is.na(bp),0])
skin.na<-row.names(dataPima[is.na(skin),0])
bmi.na<-row.names(dataPima[is.na(bmi),0])

#Combinaisons glu
glu.only<-  row.names(dataPima[which(is.na(glu) & !is.na(bmi) & !is.na(skin) & !is.na(bp) & !is.na(Insuline)),0])
glu.Insuline <-  row.names(dataPima[which(is.na(glu) & is.na (Insuline)),0])
#Combinaisons bp
#bp.only<-  row.names(dataPima[which(is.na(bp) & !is.na(skin) & !is.na(glu) & !is.na(bmi)& !is.na(Insuline)),0]) # vide
#bp.skin <-  row.names(dataPima[which(is.na(bp) & is.na (skin) &  !is.na(bmi) & !is.na(Insuline) & !is.na(glu)),0])# vide
bp.Insuline <- row.names(dataPima[which(is.na(bp) & is.na (Insuline) & !is.na(skin) & !is.na(bmi) & !is.na(glu)),0])
#bp.bmi <- row.names(dataPima[which(is.na(bp) & is.na (bmi) & !is.na(skin) & !is.na(Insuline) & !is.na(glu)),0])#vide
bp.skin.Insuline <- row.names(dataPima[which(is.na(bp) & is.na (Insuline) & is.na(skin) & !is.na(bmi) & !is.na(glu)),0])
#bp.skin.bmi <- row.names(dataPima[which(is.na(bp) & is.na (bmi) & is.na(skin) & !is.na(Insuline) & !is.na(glu)),0])#vide
bp.skin.Insuline.bmi <- row.names(dataPima[which(is.na(bp) & is.na (bmi) & is.na(skin) & is.na(Insuline) & !is.na(glu)),0])
#Combinaisons skin
#skin.only <-row.names(dataPima[which(is.na(skin) & !is.na(bp) & !is.na(bmi) & !is.na(glu) & !is.na(Insuline)),0])#vide
skin.Insuline<- row.names(dataPima[which(is.na(skin) & is.na(Insuline) & !is.na(bmi) & !is.na(glu) & !is.na(bp)),0])
#skin.bmi <- row.names(dataPima[which(is.na(skin) & is.na (bmi) & !is.na(glu) & !is.na(bp) & !is.na(Insuline)),0])"vide
skin.bmi.Insuline <- row.names(dataPima[which(is.na(skin) & is.na (bmi) & is.na(Insuline) & !is.na(bp) & !is.na(glu)),0])
#Combinaisons bmi
bmi.only<-  row.names(dataPima[which(is.na(bmi) & !is.na(skin) & !is.na(bp) & !is.na(glu) &  !is.na(Insuline)),0])
bmi.Insuline<- row.names(dataPima[which(is.na(bmi) & is.na(Insuline) & !is.na(skin) & !is.na(glu) & !is.na(bp)),0])
#Combinaisons Insuline
Insuline.only <- row.names(dataPima[which(is.na(Insuline) & !is.na(bp) & !is.na(bmi) & !is.na(skin) & !is.na(glu)),0])
#skin.bmi.Insuline.bp.glu <- row.names(dataPima[which(is.na(skin) & is.na (bmi) & is.na(Insuline) & is.na(bp) & is.na(glu)),0])#vide

nb.rows<-nrow(dataPima)
missingCateg <- replicate(nb.rows,0)
dataPima.MissingCateg <- cbind(dataPima,missingCateg)
dataPima.MissingCateg$missingCateg <- as.integer(dataPima.MissingCateg$missingCateg)

data<-as.data.frame(dataPima.MissingCateg)

data[Insuline.only,"missingCateg"]=1
data[bmi.only,"missingCateg"]=2
data[glu.only,"missingCateg"]=3
data[bmi.Insuline,"missingCateg"]=4
data[bp.Insuline,"missingCateg"]=5
data[bp.skin.Insuline,"missingCateg"]=6
data[bp.skin.Insuline.bmi,"missingCateg"]=7
data[glu.Insuline,"missingCateg"]=8
data[skin.Insuline,"missingCateg"]=9
data[skin.bmi.Insuline,"missingCateg"]=10
data$missingCateg <- factor(as.integer(data$missingCateg),levels=c(0,1,2,3,4,5,6,7,8,9,10),
labels=c("No-Missing","Insuline.only","bmi.only","glu.only","bmi.Insuline","bp.Insuline","bp.skin.Insuline","bp.skin.Insuline.bmi","glu.Insuline","skin.Insuline","skin.bmi.Insuline"))

head(data)
print("Création des catégories de données manquantes")
table(data$missingCateg)

#rm(list=ls()[-match("data",ls())]) #certaines variables sont necessaire par la suite (mis en commentaire - plante sinon)

```


**********
### 2. Exploration des données

	<https://www.kaggle.com/laozhang/statistical-learning-with-r>				
	<https://www.kaggle.com/naveenkhasa/pima-indian-diabetes-dataset>		

#### 2.1 Classification des données manqunates: MCAR/MNAR

<https://datascienceplus.com/imputing-missing-data-with-r-mice-package/>

Rapide classification de données manquantes : 
 - MCAR (missing completely at random): Donnée manquante de façon complètement aléatoire => la probabilité d’absence est la même pour toutes les observations. et ne dépend donc que de paramètres exogènes indépendants de la variable.
 - MAR  (missing at random) : Survient lorsque les données ne manquent pas de façon complètement aléatoire; la probabilité d’absence est liée à une ou plusieurs autres variables observées.
 - MNAR (missing not at random): La probabilité d’absence dépend de la variable en question.Les données MNAR induisent une perte de précision mais aussi un biais qui nécessite le recours à une analyse de sensibilité.

Recours aux librairies MICE, MASS, VIM pour visualiser les patterns du jeu de données grâce aux fonctions fluxplot() ou aggr_plot().
:-----------------------------------------------------------------------------------------------------------
Le pourcentage de données manquantes est élevé, les informations sont exhaustives pour seulement 51% des individus, ce qui jusitifie le recours à l'imputation multiple.
Le graphique des combinaisons confirme, ce qui avait déjà été mis en lumière ci-devant, à savoir la prédominance de plusieurs combinaisons : 
- Insuline + Skin
- Insuline + Skin + BP
A elle seule, la variable Insuline, quand elle est manquante, regroupe 8 patterns. La variable skin concerne 4 patterns.

Au final, il ressort que le mécanisme des données manquantes, qui concernent 5 variables du dataframe "Pima", est non-monotone, ce qui justifiera ultérieurement le recours à l'imputation multiple (joint modeling, fully conditionnal specification, ACP).

La valeur d' "influx" de la variable Insuline est plus élevée que la valeur d'"influx" de la variable Skin en dépit d'une proportion plus importante de données manquantes. Cela suggère une connection plus forte aux variables observées. Une valeur d'"outflux" très faible nous indique que la variable "Insuline", ainsi que la variable "Skin", quoique dans une moindre mesure, seront potentiellement moins utiles à l'imputation des autres variables.

```{r pattern}

aggr_plot <- aggr(data, col=c('grey','black'), numbers=TRUE, sortVars=TRUE, labels=names(data), cex.axis=.7, gap=3, ylab=c("Histogramme des données manquantes","Pattern"))
fluxplot(data[,2:6], main="Graphique Influx/Outflux")[2:3]
par(mfrow=c(1,2))
print("Nombre de patterns si Insuline manquant")
sum(md.pattern(data[,2:6], plot =F)[, "Insuline"]== 0)
print("Nombre de patterns si skin manquant")
sum(md.pattern(data[,2:6], plot =F)[,"skin"]== 0)

rm(aggr_plot)

```

* L'hypothèse MCAR semble infirmée au regard des distributions des variables Insuline et Skin comparées aux variables complètes, npreg, age et ped. A ce stade, l'hypothèse d'ignorabilité du mécanisme peut par ailleurs être maintenue. L'analyse de sensibilité nous permettra de la valider.

Nous pouvons enfin admettre que les mécanismes des variables "Insuline" et "skin" sont proches.

```{r marginplot} 
par(mfrow=c(1,1))

#Distributions marginales des variables Insuline, Skin et bp avec les autres variables incomplètes
marginplot(data[c(5,4)], col = mdc(1:2, trans = FALSE), cex.numbers = .6)
marginplot(data[c(5,3)], col = mdc(1:2, trans = FALSE), cex.numbers = .6)
marginplot(data[c(4,3)], col = mdc(1:2, trans = FALSE), cex.numbers = .6)
marginplot(data[c(5,2)], col = mdc(1:2, trans = FALSE), cex.numbers = .6)
marginplot(data[c(4,2)], col = mdc(1:2, trans = FALSE), cex.numbers = .6)
marginplot(data[c(5,6)], col = mdc(1:2, trans = FALSE), cex.numbers = .6)
marginplot(data[c(4,6)], col = mdc(1:2, trans = FALSE), cex.numbers = .6)

#Distributions marginales des mêmes variables avec les variables complètes
marginplot(data[c(5,1)], col = mdc(1:2, trans = FALSE), cex.numbers = .6)
marginplot(data[c(4,1)], col = mdc(1:2, trans = FALSE), cex.numbers = .6)
marginplot(data[c(3,1)], col = mdc(1:2, trans = FALSE), cex.numbers = .6)
marginplot(data[c(5,7)], col = mdc(1:2, trans = FALSE), cex.numbers = .6)
marginplot(data[c(4,7)], col = mdc(1:2, trans = FALSE), cex.numbers = .6)
marginplot(data[c(3,7)], col = mdc(1:2, trans = FALSE), cex.numbers = .6)
marginplot(data[c(5,8)],col = mdc(1:2, trans = FALSE), cex.numbers = .6)
marginplot(data[c(4,8)],col = mdc(1:2, trans = FALSE), cex.numbers = .6)
marginplot(data[c(3,8)],col = mdc(1:2, trans = FALSE), cex.numbers = .6)

```

### 3. Imputations

#### 3.1 Imputations avec MICE

#### 3.1.1 Imputations simples

Dans un premier temps on traite les valeurs manquantes par imputation simple avec le package MICE :
- par le biais de la méthode PMM (predictive mean matching),
- puis au moyen d'une régression linéaire - non bayésienne - stochastique.

A priori, ces imputations ne seront pas conservées en raison de la sensibilité à la spécification du modèle (pour la méthode paramétrique) et du biais souvent généré par la méthode PMM (semi paramétrique).

```{r IS, warning = F, message = FALSE, include= FALSE }

#PMM

imp.si.pmm <- mice(data, m=1, seed = 111119, print = F)

#régression stochastique avec bootstrap

imp.si.norm <- mice(data, method = "norm.nob", m = 1, maxit = 1, print = F)

```

##### 3.1.2 Imputations multiples

<https://datascienceplus.com/imputing-missing-data-with-r-mice-package/>

Nous recourons au cours d'une première étape à l'imputation multiple au moyen des méthodes Joint Modeling puis Fully Conditionnal Specification.

```{r IM, warning= F, message=F}

#JM
imp.mi.jm <- mice(data, m=5, method='norm',seed=111119, print=F)
#FCS
imp.mi.fcs <- mice(data, m=5, seed=111119, print = F)

```

#### 3.1.3 Analyses des distributions

* Analyse des distributions des variables observées et imputées pour les imputations simples

Les graphiques montrent que les imputations par régression linéaire stochastique comportent des valeurs aberrantes, négatives pour l'épaisseur de peau et le taux d'insuline.

Les distributions des valeurs observées et imputées sont proches, ce qui n'infirme ni ne confirme le mécanisme MAR.

```{r distib.is.MICE} 

#Imputations  simples
#PMM
#xyplot(imp.si.pmm,type ~ npreg + glu + bp + skin + Insuline + bmi +  ped + age, pch=18,cex=1)
densityplot(imp.si.pmm)
stripplot(imp.si.pmm, pch = 20, cex = 1.2)
#Normales
#xyplot(imp.si.norm,type ~ npreg + glu + bp + Insuline + skin + bmi +  ped + age, pch=18,cex=1)
densityplot(imp.si.norm)
stripplot(imp.si.norm, pch = 20, cex = 1.2)

```
* Analyse des distributions des variables observées et imputées pour les imputations multiples

A nouveau, certaines imputations ne sont pas plausibles : avec le modèle joint les graphiques montrent des valeurs aberrantes pour l'épaisseur de peau et le taux d'insuline. 

S'agissant de la méthode FCS, les distributions des variables glu et bmi présentent des profils très divergents pour chacune des imputations. 

```{r distib.im.MICE} }

#Imputations multiples
#JM
#xyplot(imp.si.pmm,type ~ npreg + glu + bp + skin + Insuline + bmi +  ped + age, pch=18,cex=1)
densityplot(imp.mi.jm)
stripplot(imp.mi.jm, pch = 20, cex = 1.2)
#FCS
#xyplot(imp.si.norm,type ~ npreg + glu + bp + Insuline + skin + bmi +  ped + age, pch=18,cex=1)
densityplot(imp.mi.fcs, )
stripplot(imp.mi.fcs, pch = 20, cex = 1.2)

```

#### 3.2 Imputation multiple par les méthodes d'analyse factorielle avec MIPCA

* Détermination de la dimension de l'espace de projection

```{r nb.kfold, echo=FALSE, include=FALSE }

## 1ére étape : le nombre de dimensions axes à choisir

nb.kfold <- estim_ncpPCA(data[,1:8], method.cv = "Kfold")
plot(names(nb.kfold$criterion),nb.kfold$criterion,type="b")

#setting des variables 
ncp.res<-nb.kfold$ncp

dataPima<-data[,1:maxDim]

```

nb_Pima1 = 1
nb.kfold$ncp = 5 avec insuline=>4

big différence!
Les résultats sont meilleur avec 5

Peut être utilser 4 

```{r settings} 

```

#### 3.3.1 Multiple Imputation with Bayesian method
```{r eval=FALSE, include=FALSE} 
## Multiple Imputation with Bayesian method

res.BayesMIPCA_Pima1<-MIPCA(dataPima,ncp=ncp.res,verbose=TRUE,method.mi = "Bayes")
```

```{r eval=FALSE, include=FALSE, fig.height=10, fig.width=10}
## Bayesian method
plot(res.BayesMIPCA_Pima1)
```
En changeant le nb de dimensions : de 1 à 5 le résultat est meilleur
Pb pour la variabble ped mais peu d'individus concernés => ped>1.5

```{r eval=FALSE, include=FALSE,  fig.height=10, fig.width=10}
## Diagnostics
res.over_Pima1<-Overimpute(res.BayesMIPCA_Pima1)
```

#### 3.3.2 Multiple Imputation with Bayesian method et EM

```{r eval=FALSE, include=FALSE}
res.EMBayesMIPCA_Pima1<-MIPCA(dataPima,ncp=ncp.res,verbose=TRUE,method= "EM", method.mi = "Bayes")

```

=> pas vraiment d'améliorations

```{r eval=FALSE,  fig.height=10, fig.width=10}
res.over_EMBayes_Pima1<-Overimpute(res.EMBayesMIPCA_Pima1)
```


#### 3.3.3 Multiple Imputation with Boost method

Le résultat semble meilleur

```{r eval=FALSE, include=FALSE}
# Boost method a la place de Bayesien
res.BootMIPCA_Pima1<-MIPCA(dataPima,ncp=ncp.res,verbose=TRUE,method.mi = "Boot")
```


```{r eval=FALSE,   fig.height=10, fig.width=10}
## Diagnostics
res.overBoot_Pima1<-Overimpute(res.EMBootMIPCA_Pima1)
```


#### 3.3.4 Multiple Imputation with MIPCA Boost method
```{r MIPCA, include=FALSE } 
# Boost method a la place de Bayesien
res.EMBootMIPCA_Pima1<-MIPCA(dataPima,ncp=ncp.res,verbose=TRUE,method= "EM",method.mi = "Boot")
```

Le obtenu par boostrap et method= "EM" semble le meilleur résultat

```{r Diagnostics, fig.height=10, fig.width=10}
## Diagnostics
res.overEMBoot_Pima1<-Overimpute(res.EMBootMIPCA_Pima1)
```

```{r plotRes, fig.height=10, fig.width=10}
## Diagnostics
plot(res.EMBootMIPCA_Pima1)
```


```{r stripplot} 

```


### 4. Modélisation de la variable réponse
A partir des données complétés.
Le modèle de la variable réponse: "Individus diabétique" (variable "type" : Yes/No) est un modèle logit. Regression linéaire généralisé sur les variables explicatives: npreg + glu + bp + skin + bmi +  ped + age

Regression on the multiply imputed data set and pooling with mice


```{r Modele} 
#dataPima<-data_Pima1[,1:maxDim] #dataImp
#mi<-res.BayesMIPCA_Pima1

#on reprend les données obtenues par la méhode MIPCA obtenu par boostrp et méthode EM  (3.3.4 Multiple Imputation with MIPCA Boost method)
mi.res<-res.EMBootMIPCA_Pima1

imp_Pima1<-prelim(res.mi=mi.res,X=dataPima)#creating a mids object

#MICE: with.mids Evaluate an expression in multiple imputed datasets

fit_m_sature <- with(data=imp_Pima1,exp=glm(type ~ npreg + glu + bp + skin + Insuline + bmi +  ped + age,family=binomial(link="logit")))
#equivalent d'appeler  glm.mids : fit_Pima1_m1 & fit_m_sature même chose (on obitent les mm coeff mm modele)
#fit_m_sature <- glm.mids(type ~ npreg + glu + bp + skin + bmi + Insuline + ped +  age, data = imp_Pima1,family=binomial(link="logit"))

fit_m_NoInsuline <- with(data=imp_Pima1,exp=glm(type ~ npreg + glu + bp + skin + bmi +  ped + age,family=binomial(link="logit")))
#fit_m_NoInsuline <- glm.mids(type ~ npreg + glu + bp + skin + bmi + ped +  age, data = imp_Pima1,family=binomial(link="logit"))

```
* Summary
```{r Modele_summary R2} 
#pooling et summary
res.pool_m_sature<-pool(fit_m_sature);
summary(res.pool_m_sature)#pooling

res.pool_m_NoInsuline<-pool(fit_m_NoInsuline);
summary(res.pool_m_NoInsuline)#pooling

```

* Comparaison Modele saturé avec / sans Insuline
Component pvalue is the P-value of testing whether the model fit1 is statistically different from the smaller fit0.
https://stefvanbuuren.name/mice/reference/pool.html

```{r Modele_comparaison_2} 
#comp
stat_wald<- pool.compare(fit_m_sature, fit_m_NoInsuline, method = "wald")
stat_wald$p

stat_likelihood<- pool.compare(fit_m_sature, fit_m_NoInsuline, method = "likelihood")
stat_likelihood$p

```

Petite p-value pour les deux tests => on conserve le pus grand modele (a verifier si s'interprète bien ainsi?)

* Anova => semble fonctionner... 
```{r Modele_comparaison_anova} 
anova(fit_m_sature,fit_m_NoInsuline)
```
Petite p-value => on rejette l'hypothése H0 de nullité du coefficient insuline. on garde le plus grand modèle donc.
Ce qui est conforme aux p-value du summary


```{r Modele_autres} 

fit_m_NoAge <- with(data=imp_Pima1,exp=glm(type ~ npreg + glu + bp + skin + Insuline + bmi +  ped ,family=binomial(link="logit")))
fit_m_NoSkin <- with(data=imp_Pima1,exp=glm(type ~ npreg + glu + bp  + Insuline + bmi +  ped + age ,family=binomial(link="logit")))
fit_m_NoBp <- with(data=imp_Pima1,exp=glm(type ~ npreg + glu + skin + Insuline + bmi +  ped + age,family=binomial(link="logit")))
fit_m_NoBmi <- with(data=imp_Pima1,exp=glm(type ~ npreg + glu + skin + Insuline + bp +  ped + age,family=binomial(link="logit")))
fit_m_Noglu <- with(data=imp_Pima1,exp=glm(type ~ npreg + bp + skin + Insuline + bmi +  ped + age,family=binomial(link="logit")))
fit_m_NoNpreg <- with(data=imp_Pima1,exp=glm(type ~ glu + bp + skin + Insuline + bmi +  ped + age,family=binomial(link="logit")))
```

```{r Modele_comparaison_1} 
#no Age
stat_wald<- pool.compare(fit_m_sature, fit_m_NoAge, method = "wald")
stat_wald$p
stat_likelihood<- pool.compare(fit_m_sature, fit_m_NoAge, method = "likelihood")
stat_likelihood$p

#no Skin
stat_wald<- pool.compare(fit_m_sature, fit_m_NoSkin, method = "wald")
stat_wald$p
stat_likelihood<- pool.compare(fit_m_sature, fit_m_NoSkin, method = "likelihood")
stat_likelihood$p

# No bp
stat_wald<- pool.compare(fit_m_sature, fit_m_NoBp, method = "wald")
stat_wald$p
stat_likelihood<- pool.compare(fit_m_sature, fit_m_NoBp, method = "likelihood")
stat_likelihood$p

#no bmi
stat_wald<- pool.compare(fit_m_sature, fit_m_NoBmi, method = "wald")
stat_wald$p
stat_likelihood<- pool.compare(fit_m_sature, fit_m_NoBmi, method = "likelihood")
stat_likelihood$p

#no glu
stat_wald<- pool.compare(fit_m_sature, fit_m_Noglu, method = "wald")
stat_wald$p
stat_likelihood<- pool.compare(fit_m_sature, fit_m_Noglu, method = "likelihood")
stat_likelihood$p

#no npreg
stat_wald<- pool.compare(fit_m_sature, fit_m_NoNpreg, method = "wald")
stat_wald$p
stat_likelihood<- pool.compare(fit_m_sature, fit_m_NoNpreg, method = "likelihood")
stat_likelihood$p
```


Choix du modèle saturé
A la limite on pourrait enlever la variable âge.

Pour utiliser les techniques de choix de modèles classiques, on a besoin d'avoir un dataFrame des données imputés.
Or celà ne semble pas possible.
J'ai tout de même laissé cette partie construite à partir du dataframe : res.imputePCA de MIPCA  (res.EMBootMIPCA_Pima1$res.imputePCA)   
Je serai d'avis à le supprimer si on ne trouve pas un moyen d'obtenir un dataFrame des données imputés. Ce qui ne me semble pas possible.
On a le même problème pour l'analyse PCA

Dans la vignette du package MissMDA ils utilisent : imputePCA pour faire une pca

```{r message=FALSE, warning=FALSE, include=FALSE}
## Imputation
res.comp <- imputePCA(dataPima,ncp=2)
## A PCA can be performed on the imputed data
res.pca <- PCA(res.comp$completeObs)
```


#### Choix du modèle - Utilisation de regsubsets 

```{r message=FALSE, warning=FALSE, include=FALSE}
library(leaps)
dataPCA<-res.EMBootMIPCA_Pima1$res.imputePCA
#dataPCA<-res.comp$completeObs

#DataMat=data.matrix(dataPCA)
dataFramePima<-as.data.frame(dataPCA)
dataFramePima$type <- as.logical(dataFramePima$type)

choix_modele<-regsubsets(type ~ npreg + glu + bp + Insuline + skin + bmi +  ped + age,
int=T, nbest=1,nvmax=4,method="exhaustive",data=dataFramePima)
#summary(choix_modele)
```

```{r echo=FALSE, fig.height=8, fig.width=9}
par(mfrow=c(2,2))
plot(choix_modele,scale="r2", main="Choix de modèle - critère R2", cex.axis=0.7)
plot(choix_modele,scale="adjr2", main="Choix de modèle - critère R2 ajusté", cex.axis=0.7)
plot(choix_modele,scale="Cp", main="Choix de modèle - critère Cp de Mallows", cex.axis=0.7)
plot(choix_modele,scale="bic", main="Choix de modèle - critère BIC", cex.axis=0.7)
```

La méthode step du package leaps nous fait choisir un modèle à 4 variables explicatives: npreg + glu + skin + ped

#### Choix du modèle - méthode step du package MASS à partir du modèle saturé
On reprend le modèle saturé obtenu au §2: m_sature
```{r  include= TRUE}

m_sature = glm(formula = type ~ (npreg + glu + bp + skin + Insuline + bmi +  ped + age),  family = binomial(link="logit"),  data = dataFramePima)
summary(m_sature)

```
#### Choix du modèle - Méthode progressive - step backward-forward à partir de m_sature

* Critère AIC
```{r include=FALSE}
library(MASS)
modele_step_BwdFwd_AIC <- step(m_sature, data=dataFramePima, direction="both")
#help("step")
```

* Critère BIC
```{r include=FALSE}
K<-log(dim(dataFramePima)[1])
m_StepBwdFwd_BIC <- step(m_sature, data=dataFramePima, direction="both",k=K)
#help("step")
```


##### Choix du modèle - Modèle obtenu
```{r include=TRUE}
modele_step_BwdFwd_AIC<-glm(formula = type ~ (npreg + glu + bp + skin + Insuline + bmi + ped + age), family = binomial, data = dataFramePima)
summary(modele_step_BwdFwd_AIC)
AIC(modele_step_BwdFwd_AIC)
BIC(modele_step_BwdFwd_AIC)

m_StepBwdFwd_BIC<-glm(formula = type ~ (npreg + glu + skin + Insuline + ped),family = binomial, data = dataFramePima)
summary(m_StepBwdFwd_BIC)
AIC(m_StepBwdFwd_BIC)
BIC(m_StepBwdFwd_BIC)

```

Avec le critère AIC  on obtient le modèle saturé
Avec le critère BIC : glm(npreg + glu + skin + Insuline + ped)

**********


### 5. Conclusion

Intérêt :
Les données Pima sont très utilsées (cf. Kaggle) pour autant il ne semble pas qu'un modèle d'inputation ait été utilisé.
Bien souvent les données manquantes sont supprimés ou bien imputatikon simple par moyenne.


```{r} 
```



## Annexes

### Annexe 1 : Analyse PCA - comparaison aux données non traitées 

* PCA sur les données complétées par MIPCA

```{r PCA, echo=FALSE, fig.height=10, fig.width=10}

res.pca<-PCA(dataFramePima,graph=FALSE, quali.sup = 8:9) 
summary(res.pca) 

```

*  PCA sur les données complétées par MICE
```{r PCA.mice, echo=FALSE, fig.height=10, fig.width=10}
## Diagnostics

#res.pca.mice<-PCA(completedData_mice,graph=FALSE, quali.sup = maxDim) 
#summary(res.pca.mice) 
```

*  PCA sur les données Pima de MASS (non imputées)
```{r PCA_MASS, echo=FALSE, fig.height=10, fig.width=10}
## Diagnostics
library("MASS")

dataPima.tr<-data(Pima.tr)
dataPima.te<-data(Pima.te)
#data(Pima.te)
dataPimaMASS <- rbind(Pima.tr,Pima.te)
res.pca.mass<-PCA(dataPimaMASS,graph=FALSE, quali.sup = 8) 
summary(res.pca.mass) 
```

#### 1. Choix du nombre d'axes
```{r PCA011, echo=FALSE, fig.width=10}
barplot(res.pca$eig[,2],main="Eigenvalues MIPCA",names.arg=1:nrow(res.pca$eig))
#barplot(res.pca.mice$eig[,2],main="Eigenvalues mice",names.arg=1:nrow(res.pca.mice$eig))
barplot(res.pca.mass$eig[,2],main="Eigenvalues MASS",names.arg=1:nrow(res.pca.mass$eig))
```

#### 2. Graphiques : nuage des individus et cercle de qualité des projections

* Données Pima complétées avec la méthode MIPCA du package MissMDA

```{r PCA0101, echo=FALSE, fig.height=10, fig.width=12}
#Graphique du nuage des individus - qualité de projection sur le plan principal > 0.7
#color <- ifelse(dataPCA[,9] == TRUE,"#E7B800","#00AFBB")

plot(res.pca, choix="var", axes=1:2,legend="MIPCA")
plot(res.pca,habillage=maxDim,cex=0.8, select="cos2 0.7", axes = 1:2)
plot(res.pca ,habillage=9,cex=0.8, select="cos2 0.7", axes = 1:2)

```
* Données Pima complétées avec la méthode mice du package mice

```{r PCA-MICE, echo=FALSE, fig.height=10, fig.width=12}
#Graphique du nuage des individus - qualité de projection sur le plan principal > 0.7
#color <- ifelse(dataPCA[,maxDim] == TRUE,"#E7B800","#00AFBB")

#plot(res.pca.mice, choix="var", axes=1:2,legend="MICE")
#plot(res.pca.mice,habillage=8,cex=0.8, select="cos2 0.7", axes = 1:2)
```


* Données Pima de la librairie MASS (données manquantes supprimées?)

```{r PCA0+, echo=FALSE, fig.height=10, fig.width=12}
#Graphique du nuage des individus - qualité de projection sur le plan principal > 0.7
#color <- ifelse(dataPCA[,9] == TRUE,"#E7B800","#00AFBB")

plot(res.pca.mass, choix="var", axes=1:2,legend="Pima")
plot(res.pca.mass,habillage=8,cex=0.8, select="cos2 0.7", axes = 1:2)
```

Remarque: Les données complétés par MICE et MIPCA ont une PCA similaire.
Par contre pour les données de MASS on a une transformation par rapport aux axes.
Même forme mais symétrique / à l'axe principal.

#### 3. coefficients de corrélation entre chacunes des variables et les 5 premières composantes principales 
(ce qui correspond aux coordonnées des individus sur les 5 premiers axes)
##### A partir de la fonction dimdesc

```{r 4.2.1, fig.height=15, fig.width=10, include=TRUE}
dimdesc <- dimdesc(res.pca, proba=1e-5) #, nbelements = 16)
dimdesc
```

##### Graphique de corrélation avec corrplot

```{r PCAcor_var_dim1, echo=FALSE, message=FALSE, warning=FALSE}
cor_var_dim<-round(res.pca$var$coord[,1:5],2) 
cor_var_dim.mass<-round(res.pca.mass$var$coord[,1:5],2) 
#cor_var_dim.mice<-round(res.pca.mice$var$coord[,1:5],2) 
cor_var_dim
#cor_var_dim.mice
cor_var_dim.mass

corrplot(cor_var_dim, is.corr = FALSE, tl.col="black", tl.srt=maxDim, legend="MIPCA")
#corrplot(cor_var_dim.mice, is.corr = FALSE, tl.col="black", tl.srt=maxDim, legend="mice")
corrplot(cor_var_dim.mass, is.corr = FALSE, tl.col="black", tl.srt=8)
```

#### 4. Indice de qualité de la représentation cos2

```{r cos2_var_dim1, echo=FALSE, message=FALSE, warning=FALSE}
cos2_var_dim<-round(res.pca$var$cos2[,1:5],2) 
#cos2_var_dim.mice<-round(res.pca.mice$var$cos2[,1:5],2) 
cos2_var_dim.mass<-round(res.pca.mass$var$cos2[,1:5],2) 
cos2_var_dim
#cos2_var_dim.mice
cos2_var_dim.mass
corrplot(cos2_var_dim, is.corr = FALSE, method="circle", tl.col="black", tl.srt=maxDim)
#corrplot(cos2_var_dim.mice, is.corr = FALSE, method="circle", tl.col="black", tl.srt=8)
corrplot(cos2_var_dim.mass, is.corr = FALSE, method="circle", tl.col="black", tl.srt=8)
```


#### 5. Contribution des variables à la construction des axes

```{r PCAcontrib_var_dim2, echo=FALSE}
contrib_var_dim<-round(res.pca$var$contrib[,1:5],2) 
#contrib_var_dim.mice<-round(res.pca.mice$var$contrib[,1:5],2) 
contrib_var_dim.mass<-round(res.pca.mass$var$contrib[,1:5],2) 

contrib_var_dim
#contrib_var_dim.mice
contrib_var_dim.mass
corrplot(contrib_var_dim, is.corr = FALSE, tl.col="black", tl.srt=maxDim)
#corrplot(contrib_var_dim.mice, is.corr = FALSE, tl.col="black", tl.srt=maxDim)
corrplot(contrib_var_dim.mass, is.corr = FALSE, tl.col="black", tl.srt=8)
```


### Annexe 2 : Autres méthodes MIPCA


```{r} 
```

